\section{Nominal-MPC}

\subsection{Constrained Infinite Time Optimal Control}

\textbf{what we would like to solve}

\[ \begin{aligned}
		J_\infty^\star (x(0)) = & \min_{U} \sum_{i=0}^{\infty} I(x_i, u_i)        \\
		\text{s.t} \quad        & x_{i+1} = A x_{i} + Bu_{i},\ i = 0,\dots,\infty \\
		                        & x_{i} \in \mathcal{X},\
		u_{i} \in \mathcal{U},\
		\ x_0 = x(0)
	\end{aligned} \]

- Stage cost $I(x, u)$ \textit{cost} of being in state $x$ and applying input $u$

- Optimizing over a trajectory provides a
\textbf{tradeoff between short- and long-term benefits} of actions

- We’ll see that such a control law has many beneficial properties...
... but we can’t compute it: there are an \textbf{infinite number of variables}


\textbf{what we can sometimes solve}

\[ \begin{aligned}
		J^\star (x(k)) = & \min_{U}  I_f(x_N) + \sum_{i=0}^{N-1} I(x_{i}, u_{i})                                         \\
		\text{s.t} \quad & x_{i+1} = A x_{i} + Bu_{i},\ i = 0,\dots,N-1                                                  \\
		                 & x_{i} \in \mathcal{X},\ u_{i} \in \mathcal{U},\ \mathcal{X}_N \in \mathcal{X}_f, \ x_0 = x(k)
	\end{aligned} \]

Truncate after a finite horizon:

• $I_f(x_N)$: Approximates the ‘tail’ of the cost

• $\mathcal{X}_f$: Approximates the ‘tail’ of the constraints


\subsection{Learning Objectives}

- Understand feasible set of
constrained finite horizon optimal control (CFTOC) problem

- Write quadratic cost CFTOC as QP

- Write $1−/ \infty$−norm cost CFTOC as LP

- Contrast properties of LP and QP solution

\subsection{Constrained Linear Optimal Control}

Cost Funcion

\textbf{Squared Euclidian Norm}
\[
	J(x(k)) = x_N^\top P x_N + \sum_{i=0}^{N-1}x_i^\top Q x_i + u_i R u_i
\]

N is the time horizon and X , U, Xf are polyhedral regions

\textbf{Feasible Set}

Set of states for which the optimal control problem is feasible:
%TODO: feasible set
XN =
{x0 ∈ Rn | ∃(u0 , . . . , uN−1 ) such that xi ∈ X , ui ∈ U,
i = 0, . . . , N − 1, xN ∈ Xf , where xi+1 = Axi + Bui }

Note: XN is independent of the cost.

\subsection{Constrained Optimal Control: Quadratic cost}

\subsubsection{Transform Quadratic CFTOC into QP}

Transform CFTOC as defined into QP of the following form:

\[
	\min_{z\in\mathbb{R}^n}
	\textstyle\frac{1}{2}z^\top H z + q^\top z + r
	\quad\text{s.t. }Gz\leq h,\ Az = b
\]
\subsubsection{Without Substitution}

\textbf{Idea} Keep state equations as equality constraints

(often more efficient)

\[\begin{aligned}
		J^\star(x(k)) = \min_z & \left[ z^\top \ x(k)^\top \right]
		\left[\begin{smallmatrix} \bar{H} & 0 \\ 0 & Q \end{smallmatrix}\right]
		\left[ z^\top \ x(k)^\top \right]^\top                     \\
		\text{s.t}\quad        & G_{in}z \leq w_{in} + E_{in}x(k)  \\
		                       & G_{eq}z = E_{eq}x(k)
	\end{aligned}\]

\textbf{Define variable} $z =
	\begin{bmatrix}
		x_1^\top & \dots x_N^\top & u_0^\top & \dots u_{N-1}^\top
	\end{bmatrix}^\top$

\textbf{Equalities} from system dynamics
$x_{i+1} = Ax_i + Bu_i$

\[
	G_{eq} =
	\left[
		\begin{smallmatrix}
			\mathbb{I} & & \\
			-A & \mathbb{I} & \\
			& -A & \mathbb{I} \\
			&  \cdots & \cdots
		\end{smallmatrix}
		\middle|
		\begin{smallmatrix}
			-B & & \\
			& -B & \\
			& & -B \\
			& & \cdots
		\end{smallmatrix}
		\right],
	E_{eq} =
	\left[
		\begin{smallmatrix}
			A \\
			0 \\
			\cdots \\
			0
		\end{smallmatrix}
		\right]
\]

\textbf{Inequalities}
$G_{in}z \leq w_{in} + E_{in}x(k)$
for $\mathcal{X}, \mathcal{U}, \mathcal{X}_f$
\[
	\mathcal{X}   = \{x \mid A_x x \leq b_x\},
	\mathcal{U}   = \{u \mid A_u u \leq b_u\},
	\mathcal{X}_f = \{x \mid A_f x \leq b_f\}
\]

\[
	G_{in} =
	\left[
		\begin{smallmatrix}
			0 & & & \\
			\midrule
			A_x & & & \\
			& A_x & & \\
			& & \cdots & \\
			& & & A_f \\
			\midrule
			0 & & & \\
			& 0 & & \\
			& & \cdots & \\
			& & & 0
		\end{smallmatrix}
		\middle|
		\begin{smallmatrix}
			0 & & & \\
			\midrule
			0 & & & \\
			& 0 & & \\
			& & \cdots & \\
			& & & 0 \\
			\midrule
			A_u & & & \\
			& A_u & & \\
			& & \cdots & \\
			& & & A_u
		\end{smallmatrix}
		\right]
	w_{in} =
	\left[
		\begin{smallmatrix}
			b_x \\
			\midrule
			b_x \\
			b_x \\
			\cdots \\
			b_f \\
			\midrule
			b_u \\
			b_u \\
			\cdots \\
			b_u \\
		\end{smallmatrix}
		\right]
	E_{in} =
	\left[
		\begin{smallmatrix}
			-A_x^T \\%NOTE : copy
			0 \\
			\cdots \\
			0 \\
		\end{smallmatrix}
		\right]
\]



\subsubsection{Without Substitution}

Step 1

Step 2

Step 3


\subsubsection{Quadratic Cost State Feedback Solution}



\subsection{Constrained Optimal Control: 1-Norm and ∞-Norm Cost}

%NOTE: transform to LP l_p norm construct LP with substitution mp-LP Solution Properties

\subsection{Receding Horizon Control Notation}

%TODO: Notation


\section{Invariance}

\subsection{Objectives of Constrained Control}

%NOTE: constrained control, Limit of linear controller

\subsection{Learning Objectives}

- Learn definition and meaning of invariance

(Region in which an autonomous system satisfies the constraints for all time)

- Learn definition and meaning of control invariance

(Region for which there exists a controller so that the system satisfies the constraints for all time)

- Learn how to (conceptually) compute these sets

- Learn how to compute polytopic and ellipsoidal invariant sets

\subsection{Invariance}

Invariance: Which states are “good”?


\subsection{Control Invariance}

Control Invariance: Does a good input exist?


\subsubsection{Relation to MPC}

- A control invariant set is a powerful object

- If one can compute one, it provides a direct method for synthesizing a
control law that will satisfy constraints
- The maximal control invariant set is the best any controller can do!!!

So why don’t we always compute them?
We can’t...

- Constrained linear systems : Often too complex
- (Constrained) nonlinear system : (Almost) always too complex

$\Rightarrow$ MPC implicitly describes a control invariant set
such that it’s easy to represent and compute.

\subsection{Summary Invariant Set}

- Core component of MPC problem

- Special case: Linear System / Polyhedral Constraints

-- Polyhedral invariant set

--- Can represent the maximum invariant set

--- Can be complex (many inequalities) for more than ∼ 5 − 10 states

--- Resulting MPC optimization will be a quadratic program

-- Ellipsoidal invariant set

--- Smaller than polyhedral (not the maximal invariant set)

--- Easy to compute for large dimensions

--- Fixed complexity

--- Resulting MPC optimization will be a
quadratically constrained quadratic program

Special case: Linear system, polyhedral constraints.

- Very difficult to compute

- Very complex

- Very useful

\subsection{Practical Computation of Invariant Sets}

\subsubsection{Polytopes}
%NOTE: subsection Convex sets
\subsubsection{Ellipsoids}

Ellipsoids are useful because the complexity of evaluating containment is always
quadratic in the dimension, whereas polyhedra can be arbitrarily complex.

%TODO: Largest Invarian Elipsoid set (supplementary)


\section{Feasibility and Stability}

%NOTE: Receding Horizon Control: The Motivation p2

\subsection{Learning Objectives}

- Contrast stability properties of LQR and MPC for constrained problems

- Understand why MPC by itself does not provide guarantees
on stability and constraint satisfaction

- Design MPC with closed-loop stability and constraint satisfaction

- State sufficient conditions

- Engineer terminal ingredients

- Understand main proof idea

\subsection{MPC: Key Points Illustrated}


\begin{sstTitleBox}[ForestGreen]{\textbf{\large
			MPC Mathematical Formulation
		}}

	\[\begin{aligned}
			J^\star(x(k))         & = \min \textstyle\sum_{i=0}^{N-1}
			x_i^\top Q x_i + u_i^\top R u_i                                        \\
			\mathrm{subj.\ to }\  & x_{i+1} = Ax_i + Bu_i                          \\
			                      & x_i \in \mathcal{X}, \quad u_i \in \mathcal{U} \\
			                      & x_0 = x(k)
		\end{aligned}\]

\end{sstTitleBox}

Example Saturation

LQR with saturated inputs unstable
%NOTE: Example LQR MPC comparison
MPC with input constraint not convergent to steady state but to limit cycle

MPC + with rate constraints converges

\subsection{Loss of Feasibility and Stability in MPC}

What can go wrong with “standard” MPC?

- No feasibility guarantee, i.e., the MPC problem may not have a solution

- No stability guarantee, i.e., trajectories may not converge to the origin

Example: Feasibility and stability are function of tuning

\subsubsection{Summary: Feasibility and Stability}

\textbf{Infinite-Horizon}

If we solve the RHC problem for $N = \infty$ (as done for LQR), then the
open loop trajectories are the same as the closed loop trajectories. Hence

- If problem is feasible, the closed loop trajectories will be always feasible

- If the cost is finite, then states and inputs will converge asymptotically to
the origin

\textbf{Finite-Horizon}

RHC is “short-sighted” strategy approximating infinite horizon controller.
But

- Feasibility. After some steps the finite horizon optimal control problem
may become infeasible. (Infeasibility occurs without disturbances and
model mismatch!)

- Stability. The generated control inputs may not lead to trajectories that
converge to the origin.

\subsubsection{Feasibility and stability in MPC - Solution}

\textbf{Main idea} Introduce terminal cost and constraints to explicitly ensure
feasibility and stability:


\subsection{Feasibility and Stability Guarantees in MPC}

\subsubsection{Lyapunov Stability}


\subsubsection{Feasibility and Stability of MPC: Proof}

Main steps:

• Prove recursive feasibility by showing the existence of a feasible control
sequence at all time instants when starting from a feasible initial point

• Prove stability by showing that the optimal cost function is a Lyapunov
function

Two cases:

1. Terminal constraint at zero: $x_N = 0$

2. Terminal constraint in some (convex) set: $x_N \in \mathcal{X}_f$

General notation:
%NOTE: formula
(terminal,stage cost)

\textbf{Zero terminal constraint}

Recursive feasibility

Lyapunov Stability

\textbf{Terminal set constraint}

Problem: The terminal constraint $x_N = 0$ reduces
the size of the feasible set

Goal: Use convex set $\mathcal{X}_f$ to increase the region of attraction

%NOTE: maximal Positively invarinat set 0_infty

\subsubsection{Stability of MPC - Main Result}

\begin{theorem}
	The closed-loop system under the MPC control law $u_0^\star(x)$
	is asymptotically stable and the set $\mathcal{X}_f$
	is positive invariant for the system
	$x(k+1) = Ax(k) + Bu_0^\star(x(k))$
	under the following assumptions:

	1. Stage cost is positive definite, i.e. it is strictly positive and only zero at
	the origin

	2. Terminal set is \textbf{invariant}
	under the local control law $\kappa_f(x_i)$:

	\[
		x_{i+1} = Ax_i + B\kappa_f(x_i) \in \mathcal{X}_f
		\text{ for all } x_i \in \mathcal{X}_f
	\]

	All state and input \textbf{constraints are satisfied} in $\mathcal{X}_f$:

	\[
		\mathcal{X}_f \in X, \kappa_f(x_i) \in U
		\text{ for all } x_i \in \mathcal{X}_f
	\]

	3. Terminal cost is a continuous \textbf{Lyapunov function}
	in the terminal set $\mathcal{X}_f$ and satisfies:
	\[
		I_f(x_{i+1}) - I_f(x_i) \leq
		- I(x_i, \kappa_f(x_i)) \quad
		\forall x_i \in \mathcal{X}_f
	\]
\end{theorem}

%NOTE: outline of mpc stability proof

%NOTE: Choice of terminal set (derivation)
\subsubsection{Choice of Terminal Set and Cost: Summary}

- Terminal constraint provides a sufficient condition
for feasibility and stability

- Region of attraction without terminal constraint may be larger than for
MPC with terminal constraint but characterization of region of attraction
extremely difficult %TEST: Region of attraction without terminal constraint

- $\mathcal{X}_f = 0$ simplest choice
but small region of attraction for small $N$

- Solutions available for linear systems with quadratic cost

- In practice: Enlarge horizon and check stability by sampling

- With larger horizon length $N$,
region of attraction approaches maximum control invariant set

\subsection{Extension to Nonlinear MPC}

Consider nonlinear system dynamics: $x(k+1) = g(x(k), u(k))$

%NOTE: nonlinear MPC formulation

- Presented assumptions on the terminal set and cost
did not rely on linearity

- Lyapunov stability is a general framework to analyze
stability of nonlinear dynamic systems

$\Rightarrow$ Results can be directly extended to nonlinear systems.

However, computing the sets $\mathcal{X}_f$
and function $I_f$ can be very difficult!

\subsection{Summary}

\textbf{Finite-horizon MPC may not be stable!}

\textbf{Finite-horizon MPC may not satisfy constraints for all time!}

- An infinite-horizon provides stability and invariance.

- We ‘fake’ infinite-horizon by forcing the final state to be in an invariant
set for which there exists an invariance-inducing controller, whose
infinite-horizon cost can be expressed in closed-form.

- These ideas extend to non-linear systems,
but the sets are difficult to compute.
